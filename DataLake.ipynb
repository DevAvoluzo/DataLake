{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZt7hrccCuXpC1xD5IirOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevAvoluzo/DataLake/blob/main/DataLake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwctpuk0TR4g",
        "outputId": "4f045594-e160-41e4-edb6-dc6567e003b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DADOS PARA O DATALAKE FORAM GERADOS COM SUCESSO\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados1.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       72 -0.704152       A\n",
            "1       32 -1.253291       A\n",
            "2       71 -2.431274       B\n",
            "3       27  0.471788       B\n",
            "4       30  1.549244       A\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados2.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       22 -0.144222       A\n",
            "1       80  1.301884       C\n",
            "2       37  0.867917       B\n",
            "3       83 -0.282794       C\n",
            "4       38 -0.245737       C\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados3.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       81 -0.615033       B\n",
            "1       98  1.145239       B\n",
            "2       35  0.194648       C\n",
            "3        5 -0.211786       C\n",
            "4       59  0.110851       C\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados4.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       95  0.606101       B\n",
            "1       85  0.058779       C\n",
            "2       42  2.298284       C\n",
            "3       15 -1.411752       B\n",
            "4       25  0.652476       B\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados5.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0        5 -1.121881       C\n",
            "1       16  0.016475       A\n",
            "2       84  0.691345       A\n",
            "3       92 -3.440773       A\n",
            "4       61 -0.436950       A\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados6.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       31  0.185249       B\n",
            "1       57 -0.102543       A\n",
            "2        5  0.761796       A\n",
            "3       52 -0.401743       A\n",
            "4       61  1.153943       B\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados7.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       57 -0.307708       B\n",
            "1       89  0.191919       C\n",
            "2       53 -0.487478       A\n",
            "3       96  1.100341       B\n",
            "4       87  0.980953       A\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados8.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       49 -0.211029       A\n",
            "1       17 -0.924812       B\n",
            "2       89 -0.849901       C\n",
            "3       16 -0.956829       B\n",
            "4       28  0.085689       B\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados9.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       13 -1.360064       C\n",
            "1       65  0.377056       A\n",
            "2        3  0.285377       A\n",
            "3       85 -0.679299       A\n",
            "4       81  0.429603       A\n",
            "\n",
            "INFORMAÇÕES DO ARQUIVO: data_lake/dados10.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       87  0.597722       A\n",
            "1       83  0.359215       B\n",
            "2       26  0.044318       C\n",
            "3       13 -0.497427       A\n",
            "4        8 -0.472530       C\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Importação de bibliotecas  para lidar com os dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Verifica se existe a pasta, se não existir, ele cria.\n",
        "if not os.path.exists('data_lake'):\n",
        "    os.makedirs('data_lake')\n",
        "\n",
        "# define a criaçao de arquivos, e quantas linhas vai compor cada arquivo\n",
        "num_files = 10\n",
        "num_rows_per_file = 1000\n",
        "\n",
        "# Cria um array vazio\n",
        "dfs = []\n",
        "\n",
        "# Usa um loop com base no número de arquivos:\n",
        "for i in range(num_files):\n",
        "\n",
        "  # Cria um conjunto de dados, com 3 colunas , com informações aleatórias\n",
        "    data = {\n",
        "        'coluna1': np.random.randint(0, 100, num_rows_per_file),\n",
        "        'coluna2': np.random.randn(num_rows_per_file),\n",
        "        'coluna3': np.random.choice(['A', 'B', 'C'], num_rows_per_file)\n",
        "    }\n",
        "\n",
        "    # Cria uma tabelas, sendo DataFrame, com os dados gerados:\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # cria os arquivos em CSV nomeados com os dados,\n",
        "    # e os salva no diretório 'data_lake'\n",
        "    file_name = f'data_lake/dados{i+1}.csv'\n",
        "    df.to_csv(file_name, index=False)\n",
        "\n",
        "    # Adiciona o arquivo e o DataFrame ao array:\n",
        "    dfs.append((file_name, df))\n",
        "\n",
        "print(\"DADOS PARA O DATALAKE FORAM GERADOS COM SUCESSO\")\n",
        "\n",
        "# Exibe as informações dos arquivos :\n",
        "for file_name, df in dfs:\n",
        "    print(f\"\\nINFORMAÇÕES DO ARQUIVO: {file_name}\\n\")\n",
        "    print(df.head())"
      ]
    }
  ]
}